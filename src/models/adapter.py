from __future__ import annotations
import math
import torch
import torch.nn as nn
from einops import rearrange

from .attention import ViT_DeformAttention


class ViT_D2ST_Adapter(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        self.args = cfg

        self.in_channels = cfg.ADAPTER.WIDTH
        self.out_channels = cfg.ADAPTER.WIDTH
        self.adapter_channels = int(
            cfg.ADAPTER.WIDTH * cfg.ADAPTER.ADAPTER_SCALE
        )

        self.down = nn.Linear(self.in_channels, self.adapter_channels)
        self.gelu1 = nn.GELU()

        self.pos_embed = nn.Conv3d(
            in_channels=self.adapter_channels,
            out_channels=self.adapter_channels,
            kernel_size=(3, 3, 3),
            stride=(1, 1, 1),
            padding=(1, 1, 1),
            groups=self.adapter_channels,
        )

        heads = getattr(cfg.ADAPTER, "HEADS", 4)
        groups = getattr(cfg.ADAPTER, "GROUPS", 4)

        # ğŸ”¥ ì—¬ê¸°ì„œ Tì— ë”°ë¼ spatial kernelì„ ë°”ê¿”ì¤Œ
        T = cfg.DATA.NUM_INPUT_FRAMES
        if T <= 1:
            # ì´ë¯¸ì§€ ëª¨ë“œ: time ì¶•ì€ 1ì´ë¯€ë¡œ kernel_t=1ë§Œ í—ˆìš©
            spatial_kernel = (1, 5, 5)
            spatial_stride = (1, 3, 3)
        else:
            # ë¹„ë””ì˜¤ ëª¨ë“œ: ë…¼ë¬¸ ê°’ ê·¸ëŒ€ë¡œ
            spatial_kernel = (4, 5, 5)
            spatial_stride = (4, 3, 3)

        self.s_ln = nn.LayerNorm(self.adapter_channels)
        self.s_attn = ViT_DeformAttention(
            cfg=cfg,
            dim=self.adapter_channels,
            heads=heads,
            groups=groups,
            kernel_size=spatial_kernel,
            stride=spatial_stride,
            padding=(0, 0, 0),
        )

        self.t_ln = nn.LayerNorm(self.adapter_channels)
        self.t_attn = ViT_DeformAttention(
            cfg=cfg,
            dim=self.adapter_channels,
            heads=heads,
            groups=groups,
            kernel_size=(1, 7, 7),  # time ì¶•ì€ ì›ë˜ë¶€í„° 1ì´ë¼ ì—¬ê¸°ì—” ë¬¸ì œ ì—†ìŒ
            stride=(1, 7, 7),
            padding=(0, 0, 0),
        )

        self.gelu = nn.GELU()
        self.up = nn.Linear(self.adapter_channels, self.out_channels)
        self.gelu2 = nn.GELU()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: (N, BT, C_in)
           N  = H*W + 1 (CLS í¬í•¨)
           BT = B*T
        return: (N, BT, C_in)
        """
        n, bt, c = x.shape
        x_in = x

        # H, T ë³µì›
        T = self.args.DATA.NUM_INPUT_FRAMES
        if bt % T != 0:
            raise ValueError(
                f"[ViT_D2ST_Adapter] BT({bt})ê°€ T({T})ë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì§€ì§€ ì•ŠìŒ. "
                f"Bê°€ ì •ìˆ˜ê°€ ë˜ë„ë¡ (B,T) êµ¬ì„±ì„ ë§ì¶°ì¤˜ì•¼ í•¨."
            )
        B = bt // T
        # CLS ì œì™¸í•œ í† í° ê°œìˆ˜ = H*W
        H = round(math.sqrt(n - 1))
        if H * H != (n - 1):
            # íŒ¨ì¹˜ ìˆ˜ê°€ ì •ì‚¬ê°í˜•ì´ ì•„ë‹ˆë©´ ì—¬ê¸°ì—ì„œ ì—ëŸ¬ë¥¼ ë³´ëŠ” ê²Œ ë””ë²„ê¹…ì— ë„ì›€ ë¨
            raise ValueError(
                f"[ViT_D2ST_Adapter] n-1={n-1}ì´ ì™„ì „ì œê³±ì´ ì•„ë‹˜. "
                f"H^2 = n-1ì´ ë˜ì–´ì•¼ í•˜ëŠ”ë°, H={H}ì¼ ë•Œ {H*H}."
            )

        # -------------------------
        # 1. Down-projection (token-wise)
        # -------------------------
        x = self.down(x)      # (N, BT, C')
        x = self.gelu1(x)     # (N, BT, C')

        # -------------------------
        # 2. CLS ë¶„ë¦¬
        # -------------------------
        cls = x[0:1, :, :]    # (1, BT, C')
        x_spatial = x[1:, :, :]  # (H*W, BT, C')

        # -------------------------
        # 3. 5D Positional Embedding (B, C', T, H, W)
        # -------------------------
        # (H*W, BT, C') -> (B, C', T, H, W)
        x_spatial = rearrange(
            x_spatial,
            '(h w) (b t) c -> b c t h w',
            h=H,
            t=T,
        )
        x_spatial = x_spatial + self.pos_embed(x_spatial)

        # ë‹¤ì‹œ í† í° ì‹œí€€ìŠ¤ë¡œ
        x_spatial = rearrange(
            x_spatial,
            'b c t h w -> (h w) (b t) c',
        )

        # CLS ë‹¤ì‹œ ë¶™ì´ê¸° â†’ (N, BT, C')
        x = torch.cat([cls, x_spatial], dim=0)

        # -------------------------
        # 4. Spatial / Temporal Deformable Attention
        # -------------------------
        xs = x + self.s_attn(self.s_ln(x))   # spatial branch
        xt = x + self.t_attn(self.t_ln(x))   # temporal branch

        # ë‘ branchë¥¼ í‰ê· ìœ¼ë¡œ fuse
        x = 0.5 * (xs + xt)
        x = self.gelu(x)

        # -------------------------
        # 5. Up-projection + Residual
        # -------------------------
        x = self.up(x)      # (N, BT, C_in)
        x = self.gelu2(x)
        x = x + x_in        # residual

        return x


__all__ = [
    "ViT_D2ST_Adapter",
]
